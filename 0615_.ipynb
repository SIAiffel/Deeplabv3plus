{
 "cells": [
  {
   "attachments": {
    "mobilnet_paper.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "b5f7163e",
   "metadata": {},
   "source": [
    "# 모바일넷 v2 코드 분석 \n",
    "\n",
    "* 핵심 : inverted residual block \n",
    "주의 깊게 볼 부분 \n",
    "* inverted residual block 모델 클래스 (아래 그림 마지막 pointwise)\n",
    "![mobilnet_paper.png](attachment:mobilnet_paper.png)\n",
    "\n",
    "residual block 구조 \n",
    "1. point wise(채널 연산(t)) -> conv(1*1)-batch-relu\n",
    "2. depthwise (공간 연산) -> conv(3*3)-batch-relu\n",
    "3. pointwise linear (채널 연산(c)) -> conv(1*1) - batch \n",
    "\n",
    "* mobilnet 모델 전개 부분\n",
    "노션 그림 참고 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae33e8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from torch import nn\n",
    "from torchvision.models.utils import load_state_dict_from_url\n",
    "import torch.nn.functional as F\n",
    "\n",
    "__all__ = ['MobileNetV2', 'mobilenet_v2']\n",
    "\n",
    "\n",
    "model_urls = {\n",
    "    'mobilenet_v2': 'https://download.pytorch.org/models/mobilenet_v2-b0353104.pth',\n",
    "}\n",
    "\n",
    "\n",
    "def _make_divisible(v, divisor, min_value=None):\n",
    "    \"\"\"\n",
    "    This function is taken from the original tf repo.\n",
    "    It ensures that all layers have a channel number that is divisible by 8\n",
    "    It can be seen here:\n",
    "    https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n",
    "    :param v:\n",
    "    :param divisor:\n",
    "    :param min_value:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if min_value is None:\n",
    "        min_value = divisor\n",
    "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_v < 0.9 * v:\n",
    "        new_v += divisor\n",
    "    return new_v\n",
    "\n",
    "# 모바일넷 inverted residual block 정의 \n",
    "# low feature, high feature:pointwise \n",
    "class ConvBNReLU(nn.Sequential):\n",
    "    def __init__(self, in_planes, out_planes, kernel_size=3, stride=1, dilation=1, groups=1):\n",
    "        #padding = (kernel_size - 1) // 2\n",
    "        super(ConvBNReLU, self).__init__(\n",
    "            nn.Conv2d(in_planes, out_planes, kernel_size, stride, 0, dilation=dilation, groups=groups, bias=False),\n",
    "            nn.BatchNorm2d(out_planes),\n",
    "            nn.ReLU6(inplace=True)\n",
    "        )\n",
    "#\n",
    "def fixed_padding(kernel_size, dilation):\n",
    "    kernel_size_effective = kernel_size + (kernel_size - 1) * (dilation - 1)\n",
    "    pad_total = kernel_size_effective - 1\n",
    "    pad_beg = pad_total // 2\n",
    "    pad_end = pad_total - pad_beg\n",
    "    return (pad_beg, pad_end, pad_beg, pad_end) \n",
    "\n",
    "# low - inverted residual class 3번 high - 14번 = 총 17번 사용 \n",
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(self, inp, oup, stride, dilation, expand_ratio):\n",
    "        super(InvertedResidual, self).__init__()\n",
    "        self.stride = stride\n",
    "        assert stride in [1, 2]\n",
    "\n",
    "        hidden_dim = int(round(inp * expand_ratio))\n",
    "        self.use_res_connect = self.stride == 1 and inp == oup\n",
    "\n",
    "        layers = []\n",
    "        if expand_ratio != 1:\n",
    "            # pw(위에 있던 conv+bn+relu)\n",
    "            layers.append(ConvBNReLU(inp, hidden_dim, kernel_size=1))\n",
    "\n",
    "        layers.extend([\n",
    "            # dw\n",
    "            ConvBNReLU(hidden_dim, hidden_dim, stride=stride, dilation=dilation, groups=hidden_dim),\n",
    "            # pw-linear\n",
    "            nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(oup),\n",
    "        ])\n",
    "        self.conv = nn.Sequential(*layers)\n",
    "\n",
    "        self.input_padding = fixed_padding( 3, dilation ) #패딩사용 \n",
    "\n",
    "    def forward(self, x):\n",
    "        x_pad = F.pad(x, self.input_padding) # 패딩 사용\n",
    "        if self.use_res_connect:\n",
    "            return x + self.conv(x_pad)\n",
    "        else:\n",
    "            return self.conv(x_pad)\n",
    "\n",
    "        ------------------------\n",
    "# 모델 전개 \n",
    "class MobileNetV2(nn.Module):\n",
    "    def __init__(self, num_classes=1000, output_stride=8, width_mult=1.0, inverted_residual_setting=None, round_nearest=8):\n",
    "        \"\"\"\n",
    "        MobileNet V2 main class\n",
    "\n",
    "        Args:\n",
    "            num_classes (int): Number of classes\n",
    "            width_mult (float): Width multiplier - adjusts number of channels in each layer by this amount\n",
    "            inverted_residual_setting: Network structure\n",
    "            round_nearest (int): Round the number of channels in each layer to be a multiple of this number\n",
    "            Set to 1 to turn off rounding\n",
    "        \"\"\"\n",
    "        super(MobileNetV2, self).__init__()\n",
    "        block = InvertedResidual\n",
    "        # low_feature -convBNReLU - conv2d-input 1 에서 확인 가능 \n",
    "        input_channel = 32 \n",
    "        last_channel = 1280\n",
    "        self.output_stride = output_stride\n",
    "        current_stride = 1\n",
    "        if inverted_residual_setting is None:\n",
    "            inverted_residual_setting = [\n",
    "                \n",
    "            # t, c, n, s # input 32로 들어옴 -> lower 맨 처음 convbarelu\n",
    "            # t: expansion factor (논문에서 6적용) : 입력채널이 64면 t = 6이면 출력채널 384\n",
    "            # 우리 코드 residual에서 conv2d[0](point)을 지나면 t적용 ex) in 16 -> conv2d[0] -> 96 \n",
    "            # c: output channel 수\n",
    "            #conved[2] point를 지나면 c 적용 \n",
    "            #  N: 적용갯수 S: stride\n",
    "            \n",
    "                [1, 16, 1, 1], # 1번째 residual - sequentialconv-> conv2d[1*1#채널수 32->16 #8*16*255*255\n",
    "                [6, 24, 2, 2], # 2번째 residual -> 위와 동일 채널수 16->24 #8*24*128*128\n",
    "                [6, 32, 3, 2], # high leavel feature -> invert[4] conv2d 24->32\n",
    "                [6, 64, 4, 2], # inverted [7-10]\n",
    "                [6, 96, 3, 1], # inverted[11-13]\n",
    "                [6, 160, 3, 2],# inverted[14-16]\n",
    "                [6, 320, 1, 1],# inverted[17]\n",
    "            ]\n",
    "\n",
    "        # only check the first element, assuming user knows t,c,n,s are required\n",
    "        if len(inverted_residual_setting) == 0 or len(inverted_residual_setting[0]) != 4:\n",
    "            raise ValueError(\"inverted_residual_setting should be non-empty \"\n",
    "                             \"or a 4-element list, got {}\".format(inverted_residual_setting))\n",
    "\n",
    "        # building first layer\n",
    "        input_channel = _make_divisible(input_channel * width_mult, round_nearest)\n",
    "        self.last_channel = _make_divisible(last_channel * max(1.0, width_mult), round_nearest)\n",
    "        features = [ConvBNReLU(3, input_channel, stride=2)]\n",
    "        current_stride *= 2\n",
    "        dilation=1\n",
    "        previous_dilation = 1\n",
    "\n",
    "        # building inverted residual blocks\n",
    "        for t, c, n, s in inverted_residual_setting:\n",
    "            output_channel = _make_divisible(c * width_mult, round_nearest)\n",
    "            previous_dilation = dilation\n",
    "            if current_stride == output_stride:\n",
    "                stride = 1\n",
    "                dilation *= s\n",
    "            else:\n",
    "                stride = s\n",
    "                current_stride *= s\n",
    "            output_channel = int(c * width_mult)\n",
    "\n",
    "            for i in range(n):\n",
    "                if i==0:\n",
    "                    features.append(block(input_channel, output_channel, stride, previous_dilation, expand_ratio=t))\n",
    "                else:\n",
    "                    features.append(block(input_channel, output_channel, 1, dilation, expand_ratio=t))\n",
    "                input_channel = output_channel\n",
    "        # building last several layers\n",
    "        features.append(ConvBNReLU(input_channel, self.last_channel, kernel_size=1))\n",
    "        # make it nn.Sequential\n",
    "        self.features = nn.Sequential(*features)\n",
    "\n",
    "        # building classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(self.last_channel, num_classes),\n",
    "        )\n",
    "\n",
    "        # weight initialization\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.ones_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.mean([2, 3])\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def mobilenet_v2(pretrained=False, progress=True, **kwargs):\n",
    "    \"\"\"\n",
    "    Constructs a MobileNetV2 architecture from\n",
    "    `\"MobileNetV2: Inverted Residuals and Linear Bottlenecks\" <https://arxiv.org/abs/1801.04381>`_.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = MobileNetV2(**kwargs)\n",
    "    if pretrained:\n",
    "        state_dict = load_state_dict_from_url(model_urls['mobilenet_v2'],\n",
    "                                              progress=progress)\n",
    "        model.load_state_dict(state_dict)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6af835",
   "metadata": {},
   "source": [
    "# deeplabv3+ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6b1036a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "#from .utils import _SimpleSegmentationModel\n",
    "\n",
    "\n",
    "__all__ = [\"DeepLabV3\"]\n",
    "\n",
    "\n",
    "class DeepLabV3(_SimpleSegmentationModel):\n",
    "    \"\"\"\n",
    "    Implements DeepLabV3 model from\n",
    "    `\"Rethinking Atrous Convolution for Semantic Image Segmentation\"\n",
    "    <https://arxiv.org/abs/1706.05587>`_.\n",
    "\n",
    "    Arguments:\n",
    "        backbone (nn.Module): the network used to compute the features for the model.\n",
    "            The backbone should return an OrderedDict[Tensor], with the key being\n",
    "            \"out\" for the last feature map used, and \"aux\" if an auxiliary classifier\n",
    "            is used.\n",
    "        classifier (nn.Module): module that takes the \"out\" element returned from\n",
    "            the backbone and returns a dense prediction.\n",
    "        aux_classifier (nn.Module, optional): auxiliary classifier used during training\n",
    "    \"\"\"\n",
    "    pass\n",
    "# encoder- decoder 합친 곳 전체 구조다!!\n",
    "class DeepLabHeadV3Plus(nn.Module):\n",
    "    def __init__(self, in_channels, low_level_channels, num_classes, aspp_dilate=[12, 24, 36]):\n",
    "        super(DeepLabHeadV3Plus, self).__init__()\n",
    "        self.project = nn.Sequential( \n",
    "            nn.Conv2d(low_level_channels, 48, 1, bias=False),\n",
    "            nn.BatchNorm2d(48),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.aspp = ASPP(in_channels, aspp_dilate)\n",
    "       #decoder \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Conv2d(304, 256, 3, padding=1, bias=False), #304->256\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, num_classes, 1) #256-> numclass (3) \n",
    "        ) \n",
    "        self._init_weight()\n",
    "---------------------------------\n",
    "        #  aspp 뒤에 과정 \n",
    "    def forward(self, feature):\n",
    "        low_level_feature = self.project( feature['low_level'] ) #모바일넷의 low_level features\n",
    "         #aspp의 output(8*256*32*32) -> 쌍선형보간법 *4 -> 8*265*128*128 \n",
    "         # tensorboard상 outputfeature 에서 모두 적용\n",
    "        output_feature = self.aspp(feature['out'])  \n",
    "        output_feature = F.interpolate(output_feature, size=low_level_feature.shape[2:], mode='bilinear', align_corners=False)\n",
    "        return self.classifier( torch.cat( [ low_level_feature, output_feature ], dim=1 ) )\n",
    "    # self.classifier -> decoder 본격 시작 \n",
    "    ------------------\n",
    "    def _init_weight(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "class DeepLabHead(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes, aspp_dilate=[12, 24, 36]):\n",
    "        super(DeepLabHead, self).__init__()\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            ASPP(in_channels, aspp_dilate),\n",
    "            nn.Conv2d(256, 256, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, num_classes, 1)\n",
    "        )\n",
    "        self._init_weight()\n",
    "\n",
    "    def forward(self, feature):\n",
    "        return self.classifier( feature['out'] )\n",
    "\n",
    "    def _init_weight(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "class AtrousSeparableConvolution(nn.Module):\n",
    "    \"\"\" Atrous Separable Convolution\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size,\n",
    "                            stride=1, padding=0, dilation=1, bias=True):\n",
    "        super(AtrousSeparableConvolution, self).__init__()\n",
    "        self.body = nn.Sequential(\n",
    "            # Separable Conv\n",
    "            nn.Conv2d( in_channels, in_channels, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation, bias=bias, groups=in_channels ),\n",
    "            # PointWise Conv\n",
    "            nn.Conv2d( in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=bias),\n",
    "        )\n",
    "        \n",
    "        self._init_weight()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.body(x)\n",
    "\n",
    "    def _init_weight(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "class ASPPConv(nn.Sequential):\n",
    "    def __init__(self, in_channels, out_channels, dilation):\n",
    "        modules = [\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=dilation, dilation=dilation, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        ]\n",
    "        super(ASPPConv, self).__init__(*modules)\n",
    "\n",
    "class ASPPPooling(nn.Sequential):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ASPPPooling, self).__init__(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(in_channels, out_channels, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        size = x.shape[-2:]\n",
    "        x = super(ASPPPooling, self).forward(x)\n",
    "        return F.interpolate(x, size=size, mode='bilinear', align_corners=False)\n",
    "\n",
    "class ASPP(nn.Module):\n",
    "    def __init__(self, in_channels, atrous_rates):\n",
    "        super(ASPP, self).__init__()\n",
    "        out_channels = 256\n",
    "        modules = []\n",
    "        modules.append(nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)))\n",
    "\n",
    "        rate1, rate2, rate3 = tuple(atrous_rates)\n",
    "        modules.append(ASPPConv(in_channels, out_channels, rate1))\n",
    "        modules.append(ASPPConv(in_channels, out_channels, rate2))\n",
    "        modules.append(ASPPConv(in_channels, out_channels, rate3))\n",
    "        modules.append(ASPPPooling(in_channels, out_channels))\n",
    "\n",
    "        self.convs = nn.ModuleList(modules)\n",
    "\n",
    "        self.project = nn.Sequential(\n",
    "            nn.Conv2d(5 * out_channels, out_channels, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.1),)\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = []\n",
    "        for conv in self.convs:\n",
    "            res.append(conv(x))\n",
    "        res = torch.cat(res, dim=1)\n",
    "        return self.project(res)\n",
    "\n",
    "\n",
    "\n",
    "def convert_to_separable_conv(module):\n",
    "    new_module = module\n",
    "    if isinstance(module, nn.Conv2d) and module.kernel_size[0]>1:\n",
    "        print(module.kernel_size[0])\n",
    "        print(module.kernel_size)\n",
    "        new_module = AtrousSeparableConvolution(module.in_channels,\n",
    "                                      module.out_channels, \n",
    "                                      module.kernel_size,\n",
    "                                      module.stride,\n",
    "                                      module.padding,\n",
    "                                      module.dilation,\n",
    "                                      module.bias)\n",
    "    for name, child in module.named_children():\n",
    "        new_module.add_module(name, convert_to_separable_conv(child))\n",
    "    return new_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3949e2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#    from .utils import IntermediateLayerGetter\n",
    "#    from ._deeplab import DeepLabHead, DeepLabHeadV3Plus, DeepLabV3\n",
    "#    from .backbone import resnet\n",
    "#    from .backbone import mobilenetv2\n",
    "\n",
    "def _segm_resnet(name, backbone_name, num_classes, output_stride, pretrained_backbone):\n",
    "\n",
    "    if output_stride==8:\n",
    "        replace_stride_with_dilation=[False, True, True]\n",
    "        aspp_dilate = [12, 24, 36]\n",
    "    else:\n",
    "        replace_stride_with_dilation=[False, False, True]\n",
    "        aspp_dilate = [6, 12, 18]\n",
    "\n",
    "    backbone = resnet.__dict__[backbone_name](\n",
    "        pretrained=pretrained_backbone,\n",
    "        replace_stride_with_dilation=replace_stride_with_dilation)\n",
    "    \n",
    "    inplanes = 2048\n",
    "    low_level_planes = 256\n",
    "\n",
    "    if name=='deeplabv3plus':\n",
    "        return_layers = {'layer4': 'out', 'layer1': 'low_level'}\n",
    "        classifier = DeepLabHeadV3Plus(inplanes, low_level_planes, num_classes, aspp_dilate)\n",
    "    elif name=='deeplabv3':\n",
    "        return_layers = {'layer4': 'out'}\n",
    "        classifier = DeepLabHead(inplanes , num_classes, aspp_dilate)\n",
    "    backbone = IntermediateLayerGetter(backbone, return_layers=return_layers)\n",
    "\n",
    "    model = DeepLabV3(backbone, classifier)\n",
    "    return model\n",
    "\n",
    "def _segm_mobilenet(name, backbone_name, num_classes, output_stride, pretrained_backbone):\n",
    "    if output_stride==8:\n",
    "        aspp_dilate = [12, 24, 36]\n",
    "    else:\n",
    "        aspp_dilate = [6, 12, 18]\n",
    "\n",
    "    backbone = mobilenet_v2(pretrained=pretrained_backbone, output_stride=output_stride)\n",
    "    \n",
    "    # rename layers\n",
    "    backbone.low_level_features = backbone.features[0:4]\n",
    "    backbone.high_level_features = backbone.features[4:-1]\n",
    "    backbone.features = None\n",
    "    backbone.classifier = None\n",
    "\n",
    "    inplanes = 320\n",
    "    low_level_planes = 24\n",
    "    \n",
    "    if name=='deeplabv3plus':\n",
    "        return_layers = {'high_level_features': 'out', 'low_level_features': 'low_level'}\n",
    "        classifier = DeepLabHeadV3Plus(inplanes, low_level_planes, num_classes, aspp_dilate)\n",
    "    elif name=='deeplabv3':\n",
    "        return_layers = {'high_level_features': 'out'}\n",
    "        classifier = DeepLabHead(inplanes , num_classes, aspp_dilate)\n",
    "    backbone = IntermediateLayerGetter(backbone, return_layers=return_layers)\n",
    "\n",
    "    model = DeepLabV3(backbone, classifier)\n",
    "    return model\n",
    "\n",
    "def _load_model(arch_type, backbone, num_classes, output_stride, pretrained_backbone):\n",
    "\n",
    "    if backbone=='mobilenetv2':\n",
    "        model = _segm_mobilenet(arch_type, backbone, num_classes, output_stride=output_stride, pretrained_backbone=pretrained_backbone)\n",
    "    elif backbone.startswith('resnet'):\n",
    "        model = _segm_resnet(arch_type, backbone, num_classes, output_stride=output_stride, pretrained_backbone=pretrained_backbone)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    return model\n",
    "\n",
    "\n",
    "# Deeplab v3\n",
    "\n",
    "def deeplabv3_resnet50(num_classes=21, output_stride=8, pretrained_backbone=True):\n",
    "    \"\"\"Constructs a DeepLabV3 model with a ResNet-50 backbone.\n",
    "\n",
    "    Args:\n",
    "        num_classes (int): number of classes.\n",
    "        output_stride (int): output stride for deeplab.\n",
    "        pretrained_backbone (bool): If True, use the pretrained backbone.\n",
    "    \"\"\"\n",
    "    return _load_model('deeplabv3', 'resnet50', num_classes, output_stride=output_stride, pretrained_backbone=pretrained_backbone)\n",
    "\n",
    "def deeplabv3_resnet101(num_classes=21, output_stride=8, pretrained_backbone=True):\n",
    "    \"\"\"Constructs a DeepLabV3 model with a ResNet-101 backbone.\n",
    "\n",
    "    Args:\n",
    "        num_classes (int): number of classes.\n",
    "        output_stride (int): output stride for deeplab.\n",
    "        pretrained_backbone (bool): If True, use the pretrained backbone.\n",
    "    \"\"\"\n",
    "    return _load_model('deeplabv3', 'resnet101', num_classes, output_stride=output_stride, pretrained_backbone=pretrained_backbone)\n",
    "\n",
    "def deeplabv3_mobilenet(num_classes=21, output_stride=8, pretrained_backbone=True, **kwargs):\n",
    "    \"\"\"Constructs a DeepLabV3 model with a MobileNetv2 backbone.\n",
    "\n",
    "    Args:\n",
    "        num_classes (int): number of classes.\n",
    "        output_stride (int): output stride for deeplab.\n",
    "        pretrained_backbone (bool): If True, use the pretrained backbone.\n",
    "    \"\"\"\n",
    "    return _load_model('deeplabv3', 'mobilenetv2', num_classes, output_stride=output_stride, pretrained_backbone=pretrained_backbone)\n",
    "\n",
    "\n",
    "# Deeplab v3+\n",
    "\n",
    "def deeplabv3plus_resnet50(num_classes=21, output_stride=8, pretrained_backbone=True):\n",
    "    \"\"\"Constructs a DeepLabV3 model with a ResNet-50 backbone.\n",
    "\n",
    "    Args:\n",
    "        num_classes (int): number of classes.\n",
    "        output_stride (int): output stride for deeplab.\n",
    "        pretrained_backbone (bool): If True, use the pretrained backbone.\n",
    "    \"\"\"\n",
    "    return _load_model('deeplabv3plus', 'resnet50', num_classes, output_stride=output_stride, pretrained_backbone=pretrained_backbone)\n",
    "\n",
    "\n",
    "def deeplabv3plus_resnet101(num_classes=21, output_stride=8, pretrained_backbone=True):\n",
    "    \"\"\"Constructs a DeepLabV3+ model with a ResNet-101 backbone.\n",
    "\n",
    "    Args:\n",
    "        num_classes (int): number of classes.\n",
    "        output_stride (int): output stride for deeplab.\n",
    "        pretrained_backbone (bool): If True, use the pretrained backbone.\n",
    "    \"\"\"\n",
    "    return _load_model('deeplabv3plus', 'resnet101', num_classes, output_stride=output_stride, pretrained_backbone=pretrained_backbone)\n",
    "\n",
    "\n",
    "def deeplabv3plus_mobilenet(num_classes=21, output_stride=8, pretrained_backbone=True):\n",
    "    \"\"\"Constructs a DeepLabV3+ model with a MobileNetv2 backbone.\n",
    "\n",
    "    Args:\n",
    "        num_classes (int): number of classes.\n",
    "        output_stride (int): output stride for deeplab.\n",
    "        pretrained_backbone (bool): If True, use the pretrained backbone.\n",
    "    \"\"\"\n",
    "    return _load_model('deeplabv3plus', 'mobilenetv2', num_classes, output_stride=output_stride, pretrained_backbone=pretrained_backbone)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62aeb818",
   "metadata": {},
   "source": [
    "# 전체 모델 eval \n",
    "\n",
    "상세한 커널 사이즈랑 stride 알 수 있음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104e3e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DeepLabV3(\n",
    "  (backbone): IntermediateLayerGetter( #모바일넷 \n",
    "    (low_level_features): Sequential(\n",
    "      (0): ConvBNReLU(\n",
    "        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
    "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        (2): ReLU6(inplace=True)\n",
    "      )\n",
    "      (1): InvertedResidual(\n",
    "        (conv): Sequential(\n",
    "          (0): ConvBNReLU(\n",
    "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), groups=32, bias=False)\n",
    "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            (2): ReLU6(inplace=True)\n",
    "          )\n",
    "          (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        )\n",
    "      )\n",
    "      (2): InvertedResidual(\n",
    "        (conv): Sequential(\n",
    "          (0): ConvBNReLU(\n",
    "            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            (2): ReLU6(inplace=True)\n",
    "          )\n",
    "          (1): ConvBNReLU(\n",
    "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), groups=96, bias=False)\n",
    "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            (2): ReLU6(inplace=True)\n",
    "          )\n",
    "          (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        )\n",
    "      )\n",
    "      (3): InvertedResidual(\n",
    "        (conv): Sequential(\n",
    "          (0): ConvBNReLU(\n",
    "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            (2): ReLU6(inplace=True)\n",
    "          )\n",
    "          (1): ConvBNReLU(\n",
    "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False)\n",
    "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            (2): ReLU6(inplace=True)\n",
    "          )\n",
    "          (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        )\n",
    "      )\n",
    "    )\n",
    "    (high_level_features): Sequential(\n",
    "      (4): InvertedResidual(\n",
    "        (conv): Sequential(\n",
    "          (0): ConvBNReLU(\n",
    "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            (2): ReLU6(inplace=True)\n",
    "          )\n",
    "          (1): ConvBNReLU(\n",
    "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), groups=144, bias=False)\n",
    "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            (2): ReLU6(inplace=True)\n",
    "          )\n",
    "          (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        )\n",
    "      )\n",
    "      (5): InvertedResidual(\n",
    "        (conv): Sequential(\n",
    "          (0): ConvBNReLU(\n",
    "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            (2): ReLU6(inplace=True)\n",
    "          )\n",
    "          (1): ConvBNReLU(\n",
    "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
    "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            (2): ReLU6(inplace=True)\n",
    "          )\n",
    "          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        )\n",
    "      )\n",
    "      (6): InvertedResidual(\n",
    "        (conv): Sequential(\n",
    "          (0): ConvBNReLU(\n",
    "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            (2): ReLU6(inplace=True)\n",
    "          )\n",
    "          (1): ConvBNReLU(\n",
    "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
    "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            (2): ReLU6(inplace=True)\n",
    "          )\n",
    "          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        )\n",
    "      )\n",
    "      (7): InvertedResidual(\n",
    "        (conv): Sequential(\n",
    "          (0): ConvBNReLU(\n",
    "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            (2): ReLU6(inplace=True)\n",
    "          )\n",
    "          (1): ConvBNReLU(\n",
    "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), groups=192, bias=False)\n",
    "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            (2): ReLU6(inplace=True)\n",
    "          )\n",
    "          (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        )\n",
    "      )\n",
    "      (8): InvertedResidual(\n",
    "        (conv): Sequential(\n",
    "          (0): ConvBNReLU(\n",
    "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            (2): ReLU6(inplace=True)\n",
    "          )\n",
    "          (1): ConvBNReLU(\n",
    "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
    "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            (2): ReLU6(inplace=True)\n",
    "          )\n",
    "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        )\n",
    "      )\n",
    "      (9): InvertedResidual(\n",
    "        (conv): Sequential(\n",
    "          (0): ConvBNReLU(\n",
    "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            (2): ReLU6(inplace=True)\n",
    "          )\n",
    "          (1): ConvBNReLU(\n",
    "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
    "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            (2): ReLU6(inplace=True)\n",
    "          )\n",
    "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        )\n",
    "      )\n",
    "      (10): InvertedResidual(\n",
    "        (conv): Sequential(\n",
    "          (0): ConvBNReLU(\n",
    "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            (2): ReLU6(inplace=True)\n",
    "          )\n",
    "          (1): ConvBNReLU(\n",
    "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
    "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            (2): ReLU6(inplace=True)\n",
    "          )\n",
    "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        )\n",
    "      )\n",
    "      (11): InvertedResidual(\n",
    "        (conv): Sequential(\n",
    "          (0): ConvBNReLU(\n",
    "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            (2): ReLU6(inplace=True)\n",
    "          )\n",
    "          (1): ConvBNReLU(\n",
    "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
    "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            (2): ReLU6(inplace=True)\n",
    "          )\n",
    "          (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        )\n",
    "      )\n",
    "      (12): InvertedResidual(\n",
    "        (conv): Sequential(\n",
    "          (0): ConvBNReLU(\n",
    "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            (2): ReLU6(inplace=True)\n",
    "          )\n",
    "          (1): ConvBNReLU(\n",
    "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
    "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            (2): ReLU6(inplace=True)\n",
    "          )\n",
    "          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        )\n",
    "      )\n",
    "      (13): InvertedResidual(\n",
    "        (conv): Sequential(\n",
    "          (0): ConvBNReLU(\n",
    "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            (2): ReLU6(inplace=True)\n",
    "          )\n",
    "          (1): ConvBNReLU(\n",
    "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
    "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            (2): ReLU6(inplace=True)\n",
    "          )\n",
    "          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        )\n",
    "      )\n",
    "      (14): InvertedResidual(\n",
    "        (conv): Sequential(\n",
    "          (0): ConvBNReLU(\n",
    "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            (2): ReLU6(inplace=True)\n",
    "          )\n",
    "          (1): ConvBNReLU(\n",
    "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
    "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            (2): ReLU6(inplace=True)\n",
    "          )\n",
    "          (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        )\n",
    "      )\n",
    "      (15): InvertedResidual(\n",
    "        (conv): Sequential(\n",
    "          (0): ConvBNReLU(\n",
    "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            (2): ReLU6(inplace=True)\n",
    "          )\n",
    "          (1): ConvBNReLU(\n",
    "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2), groups=960, bias=False)\n",
    "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            (2): ReLU6(inplace=True)\n",
    "          )\n",
    "          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        )\n",
    "      )\n",
    "      (16): InvertedResidual(\n",
    "        (conv): Sequential(\n",
    "          (0): ConvBNReLU(\n",
    "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            (2): ReLU6(inplace=True)\n",
    "          )\n",
    "          (1): ConvBNReLU(\n",
    "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2), groups=960, bias=False)\n",
    "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            (2): ReLU6(inplace=True)\n",
    "          )\n",
    "          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        )\n",
    "      )\n",
    "      (17): InvertedResidual(\n",
    "        (conv): Sequential(\n",
    "          (0): ConvBNReLU(\n",
    "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            (2): ReLU6(inplace=True)\n",
    "          )\n",
    "          (1): ConvBNReLU(\n",
    "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2), groups=960, bias=False)\n",
    "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            (2): ReLU6(inplace=True)\n",
    "          )\n",
    "          (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "          (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        )\n",
    "      )\n",
    "    )\n",
    "  )  # 이 아래부터 deeplabv3+ encoder-decoder\n",
    "  (classifier): DeepLabHeadV3Plus( \n",
    "    (project): Sequential(\n",
    "      (0): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "      (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "      (2): ReLU(inplace=True)\n",
    "    )\n",
    "\n",
    "    (aspp): ASPP( \n",
    "      (convs): ModuleList(\n",
    "        (0): Sequential( #1*1conv\n",
    "          (0): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "          (2): ReLU(inplace=True)\n",
    "        )\n",
    "  (atrous conv) \n",
    "        (1): ASPPConv(\n",
    "          (0): AtrousSeparableConvolution(\n",
    "            (body): Sequential(\n",
    "              (0): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), groups=320, bias=False)\n",
    "              (1): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) # conv1*1\n",
    "            )\n",
    "          )\n",
    "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "          (2): ReLU(inplace=True)\n",
    "        )\n",
    "        (2): ASPPConv(\n",
    "          (0): AtrousSeparableConvolution(\n",
    "            (body): Sequential(\n",
    "              (0): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=320, bias=False)\n",
    "              (1): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "            )\n",
    "          )\n",
    "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "          (2): ReLU(inplace=True)\n",
    "        )\n",
    "        (3): ASPPConv(\n",
    "          (0): AtrousSeparableConvolution(\n",
    "            (body): Sequential(\n",
    "              (0): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=320, bias=False)\n",
    "              (1): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "            )\n",
    "          )\n",
    "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "          (2): ReLU(inplace=True)\n",
    "        )\n",
    "        (4): ASPPPooling(\n",
    "          (0): AdaptiveAvgPool2d(output_size=1)\n",
    "          (1): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "          (3): ReLU(inplace=True)\n",
    "        )\n",
    "      )\n",
    "      (project): Sequential(\n",
    "      #(1-4) 다 합친것+1*1 conv? \n",
    "        (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) \n",
    "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        (2): ReLU(inplace=True)\n",
    "        (3): Dropout(p=0.1, inplace=False)\n",
    "      ) --------aspp 끝 \n",
    "    )\n",
    "    (classifier): Sequential(\n",
    "      (0): AtrousSeparableConvolution(   # \n",
    "        (body): Sequential(\n",
    "          (0): Conv2d(304, 304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=304, bias=False)\n",
    "          (1): Conv2d(304, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "        )\n",
    "      )\n",
    "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) \n",
    "      (2): ReLU(inplace=True)\n",
    "      (3): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1)) #1*1\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6441bb",
   "metadata": {},
   "source": [
    "# 밑에 코드는 참고!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "488abedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from collections import OrderedDict\n",
    "\n",
    "class _SimpleSegmentationModel(nn.Module):\n",
    "    def __init__(self, backbone, classifier):\n",
    "        super(_SimpleSegmentationModel, self).__init__()\n",
    "        self.backbone = backbone\n",
    "        self.classifier = classifier\n",
    "        \n",
    "    def forward(self, x):\n",
    "        input_shape = x.shape[-2:]\n",
    "        print()\n",
    "        features = self.backbone(x)\n",
    "        x = self.classifier(features)\n",
    "        x = F.interpolate(x, size=input_shape, mode='bilinear', align_corners=False)\n",
    "        return x\n",
    "\n",
    "\n",
    "class IntermediateLayerGetter(nn.ModuleDict):\n",
    "    \"\"\"\n",
    "    Module wrapper that returns intermediate layers from a model\n",
    "\n",
    "    It has a strong assumption that the modules have been registered\n",
    "    into the model in the same order as they are used.\n",
    "    This means that one should **not** reuse the same nn.Module\n",
    "    twice in the forward if you want this to work.\n",
    "\n",
    "    Additionally, it is only able to query submodules that are directly\n",
    "    assigned to the model. So if `model` is passed, `model.feature1` can\n",
    "    be returned, but not `model.feature1.layer2`.\n",
    "\n",
    "    Arguments:\n",
    "        model (nn.Module): model on which we will extract the features\n",
    "        return_layers (Dict[name, new_name]): a dict containing the names\n",
    "            of the modules for which the activations will be returned as\n",
    "            the key of the dict, and the value of the dict is the name\n",
    "            of the returned activation (which the user can specify).\n",
    "\n",
    "    Examples::\n",
    "\n",
    "        >>> m = torchvision.models.resnet18(pretrained=True)\n",
    "        >>> # extract layer1 and layer3, giving as names `feat1` and feat2`\n",
    "        >>> new_m = torchvision.models._utils.IntermediateLayerGetter(m,\n",
    "        >>>     {'layer1': 'feat1', 'layer3': 'feat2'})\n",
    "        >>> out = new_m(torch.rand(1, 3, 224, 224))\n",
    "        >>> print([(k, v.shape) for k, v in out.items()])\n",
    "        >>>     [('feat1', torch.Size([1, 64, 56, 56])),\n",
    "        >>>      ('feat2', torch.Size([1, 256, 14, 14]))]\n",
    "    \"\"\"\n",
    "    def __init__(self, model, return_layers):\n",
    "        if not set(return_layers).issubset([name for name, _ in model.named_children()]):\n",
    "            raise ValueError(\"return_layers are not present in model\")\n",
    "\n",
    "        orig_return_layers = return_layers\n",
    "        return_layers = {k: v for k, v in return_layers.items()}\n",
    "        layers = OrderedDict()\n",
    "        for name, module in model.named_children():\n",
    "            layers[name] = module\n",
    "            if name in return_layers:\n",
    "                del return_layers[name]\n",
    "            if not return_layers:\n",
    "                break\n",
    "\n",
    "        super(IntermediateLayerGetter, self).__init__(layers)\n",
    "        self.return_layers = orig_return_layers\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = OrderedDict()\n",
    "        for name, module in self.named_children():\n",
    "            x = module(x)\n",
    "            if name in self.return_layers:\n",
    "                out_name = self.return_layers[name]\n",
    "                out[out_name] = x\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e8e1c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CKPT_PATH = '/home/aiffel-dj54/aiffel/siaiffel/DeepLabV3Plus-Pytorch-master/checkpoints/best_deeplabv3plus_mobilenet_satellites_multi_os16.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9e6ce16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkpoint = torch.load(CKPT_PATH, map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6407fecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import torchvision.transforms.functional as F\n",
    "import random \n",
    "import numbers\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "#\n",
    "#  Extended Transforms for Semantic Segmentation\n",
    "#\n",
    "class ExtRandomHorizontalFlip(object):\n",
    "    \"\"\"Horizontally flip the given PIL Image randomly with a given probability.\n",
    "\n",
    "    Args:\n",
    "        p (float): probability of the image being flipped. Default value is 0.5\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, p=0.5):\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, img, lbl):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (PIL Image): Image to be flipped.\n",
    "\n",
    "        Returns:\n",
    "            PIL Image: Randomly flipped image.\n",
    "        \"\"\"\n",
    "        if random.random() < self.p:\n",
    "            return F.hflip(img), F.hflip(lbl)\n",
    "        return img, lbl\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(p={})'.format(self.p)\n",
    "\n",
    "\n",
    "\n",
    "class ExtCompose(object):\n",
    "    \"\"\"Composes several transforms together.\n",
    "    Args:\n",
    "        transforms (list of ``Transform`` objects): list of transforms to compose.\n",
    "    Example:\n",
    "        >>> transforms.Compose([\n",
    "        >>>     transforms.CenterCrop(10),\n",
    "        >>>     transforms.ToTensor(),\n",
    "        >>> ])\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, img, lbl):\n",
    "        for t in self.transforms:\n",
    "            img, lbl = t(img, lbl)\n",
    "        return img, lbl\n",
    "\n",
    "    def __repr__(self):\n",
    "        format_string = self.__class__.__name__ + '('\n",
    "        for t in self.transforms:\n",
    "            format_string += '\\n'\n",
    "            format_string += '    {0}'.format(t)\n",
    "        format_string += '\\n)'\n",
    "        return format_string\n",
    "\n",
    "\n",
    "class ExtCenterCrop(object):\n",
    "    \"\"\"Crops the given PIL Image at the center.\n",
    "    Args:\n",
    "        size (sequence or int): Desired output size of the crop. If size is an\n",
    "            int instead of sequence like (h, w), a square crop (size, size) is\n",
    "            made.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size):\n",
    "        if isinstance(size, numbers.Number):\n",
    "            self.size = (int(size), int(size))\n",
    "        else:\n",
    "            self.size = size\n",
    "\n",
    "    def __call__(self, img, lbl):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (PIL Image): Image to be cropped.\n",
    "        Returns:\n",
    "            PIL Image: Cropped image.\n",
    "        \"\"\"\n",
    "        return F.center_crop(img, self.size), F.center_crop(lbl, self.size)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(size={0})'.format(self.size)\n",
    "\n",
    "\n",
    "class ExtRandomScale(object):\n",
    "    def __init__(self, scale_range, interpolation=Image.BILINEAR):\n",
    "        self.scale_range = scale_range\n",
    "        self.interpolation = interpolation\n",
    "\n",
    "    def __call__(self, img, lbl):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (PIL Image): Image to be scaled.\n",
    "            lbl (PIL Image): Label to be scaled.\n",
    "        Returns:\n",
    "            PIL Image: Rescaled image.\n",
    "            PIL Image: Rescaled label.\n",
    "        \"\"\"\n",
    "        assert img.size == lbl.size\n",
    "        scale = random.uniform(self.scale_range[0], self.scale_range[1])\n",
    "        target_size = ( int(img.size[1]*scale), int(img.size[0]*scale) )\n",
    "        return F.resize(img, target_size, self.interpolation), F.resize(lbl, target_size, Image.NEAREST)\n",
    "\n",
    "    def __repr__(self):\n",
    "        interpolate_str = _pil_interpolation_to_str[self.interpolation]\n",
    "        return self.__class__.__name__ + '(size={0}, interpolation={1})'.format(self.size, interpolate_str)\n",
    "\n",
    "class ExtScale(object):\n",
    "    \"\"\"Resize the input PIL Image to the given scale.\n",
    "    Args:\n",
    "        Scale (sequence or int): scale factors\n",
    "        interpolation (int, optional): Desired interpolation. Default is\n",
    "            ``PIL.Image.BILINEAR``\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, scale, interpolation=Image.BILINEAR):\n",
    "        self.scale = scale\n",
    "        self.interpolation = interpolation\n",
    "\n",
    "    def __call__(self, img, lbl):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (PIL Image): Image to be scaled.\n",
    "            lbl (PIL Image): Label to be scaled.\n",
    "        Returns:\n",
    "            PIL Image: Rescaled image.\n",
    "            PIL Image: Rescaled label.\n",
    "        \"\"\"\n",
    "        assert img.size == lbl.size\n",
    "        target_size = ( int(img.size[1]*self.scale), int(img.size[0]*self.scale) ) # (H, W)\n",
    "        return F.resize(img, target_size, self.interpolation), F.resize(lbl, target_size, Image.NEAREST)\n",
    "\n",
    "    def __repr__(self):\n",
    "        interpolate_str = _pil_interpolation_to_str[self.interpolation]\n",
    "        return self.__class__.__name__ + '(size={0}, interpolation={1})'.format(self.size, interpolate_str)\n",
    "\n",
    "\n",
    "class ExtRandomRotation(object):\n",
    "    \"\"\"Rotate the image by angle.\n",
    "    Args:\n",
    "        degrees (sequence or float or int): Range of degrees to select from.\n",
    "            If degrees is a number instead of sequence like (min, max), the range of degrees\n",
    "            will be (-degrees, +degrees).\n",
    "        resample ({PIL.Image.NEAREST, PIL.Image.BILINEAR, PIL.Image.BICUBIC}, optional):\n",
    "            An optional resampling filter.\n",
    "            See http://pillow.readthedocs.io/en/3.4.x/handbook/concepts.html#filters\n",
    "            If omitted, or if the image has mode \"1\" or \"P\", it is set to PIL.Image.NEAREST.\n",
    "        expand (bool, optional): Optional expansion flag.\n",
    "            If true, expands the output to make it large enough to hold the entire rotated image.\n",
    "            If false or omitted, make the output image the same size as the input image.\n",
    "            Note that the expand flag assumes rotation around the center and no translation.\n",
    "        center (2-tuple, optional): Optional center of rotation.\n",
    "            Origin is the upper left corner.\n",
    "            Default is the center of the image.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, degrees, resample=False, expand=False, center=None):\n",
    "        if isinstance(degrees, numbers.Number):\n",
    "            if degrees < 0:\n",
    "                raise ValueError(\"If degrees is a single number, it must be positive.\")\n",
    "            self.degrees = (-degrees, degrees)\n",
    "        else:\n",
    "            if len(degrees) != 2:\n",
    "                raise ValueError(\"If degrees is a sequence, it must be of len 2.\")\n",
    "            self.degrees = degrees\n",
    "\n",
    "        self.resample = resample\n",
    "        self.expand = expand\n",
    "        self.center = center\n",
    "\n",
    "    @staticmethod\n",
    "    def get_params(degrees):\n",
    "        \"\"\"Get parameters for ``rotate`` for a random rotation.\n",
    "        Returns:\n",
    "            sequence: params to be passed to ``rotate`` for random rotation.\n",
    "        \"\"\"\n",
    "        angle = random.uniform(degrees[0], degrees[1])\n",
    "\n",
    "        return angle\n",
    "\n",
    "    def __call__(self, img, lbl):\n",
    "        \"\"\"\n",
    "            img (PIL Image): Image to be rotated.\n",
    "            lbl (PIL Image): Label to be rotated.\n",
    "        Returns:\n",
    "            PIL Image: Rotated image.\n",
    "            PIL Image: Rotated label.\n",
    "        \"\"\"\n",
    "\n",
    "        angle = self.get_params(self.degrees)\n",
    "\n",
    "        return F.rotate(img, angle, self.resample, self.expand, self.center), F.rotate(lbl, angle, self.resample, self.expand, self.center)\n",
    "\n",
    "    def __repr__(self):\n",
    "        format_string = self.__class__.__name__ + '(degrees={0}'.format(self.degrees)\n",
    "        format_string += ', resample={0}'.format(self.resample)\n",
    "        format_string += ', expand={0}'.format(self.expand)\n",
    "        if self.center is not None:\n",
    "            format_string += ', center={0}'.format(self.center)\n",
    "        format_string += ')'\n",
    "        return format_string\n",
    "\n",
    "class ExtRandomHorizontalFlip(object):\n",
    "    \"\"\"Horizontally flip the given PIL Image randomly with a given probability.\n",
    "    Args:\n",
    "        p (float): probability of the image being flipped. Default value is 0.5\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, p=0.5):\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, img, lbl):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (PIL Image): Image to be flipped.\n",
    "        Returns:\n",
    "            PIL Image: Randomly flipped image.\n",
    "        \"\"\"\n",
    "        if random.random() < self.p:\n",
    "            return F.hflip(img), F.hflip(lbl)\n",
    "        return img, lbl\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(p={})'.format(self.p)\n",
    "\n",
    "\n",
    "class ExtRandomVerticalFlip(object):\n",
    "    \"\"\"Vertically flip the given PIL Image randomly with a given probability.\n",
    "    Args:\n",
    "        p (float): probability of the image being flipped. Default value is 0.5\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, p=0.5):\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, img, lbl):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (PIL Image): Image to be flipped.\n",
    "            lbl (PIL Image): Label to be flipped.\n",
    "        Returns:\n",
    "            PIL Image: Randomly flipped image.\n",
    "            PIL Image: Randomly flipped label.\n",
    "        \"\"\"\n",
    "        if random.random() < self.p:\n",
    "            return F.vflip(img), F.vflip(lbl)\n",
    "        return img, lbl\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(p={})'.format(self.p)\n",
    "\n",
    "class ExtPad(object):\n",
    "    def __init__(self, diviser=32):\n",
    "        self.diviser = diviser\n",
    "    \n",
    "    def __call__(self, img, lbl):\n",
    "        h, w = img.size\n",
    "        ph = (h//32+1)*32 - h if h%32!=0 else 0\n",
    "        pw = (w//32+1)*32 - w if w%32!=0 else 0\n",
    "        im = F.pad(img, ( pw//2, pw-pw//2, ph//2, ph-ph//2) )\n",
    "        lbl = F.pad(lbl, ( pw//2, pw-pw//2, ph//2, ph-ph//2))\n",
    "        return im, lbl\n",
    "\n",
    "class ExtToTensor(object):\n",
    "    \"\"\"Convert a ``PIL Image`` or ``numpy.ndarray`` to tensor.\n",
    "    Converts a PIL Image or numpy.ndarray (H x W x C) in the range\n",
    "    [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0].\n",
    "    \"\"\"\n",
    "    def __init__(self, normalize=True, target_type='uint8'):\n",
    "        self.normalize = normalize\n",
    "        self.target_type = target_type\n",
    "    def __call__(self, pic, lbl):\n",
    "        \"\"\"\n",
    "        Note that labels will not be normalized to [0, 1].\n",
    "        Args:\n",
    "            pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\n",
    "            lbl (PIL Image or numpy.ndarray): Label to be converted to tensor. \n",
    "        Returns:\n",
    "            Tensor: Converted image and label\n",
    "        \"\"\"\n",
    "        if self.normalize:\n",
    "            return F.to_tensor(pic), torch.from_numpy( np.array( lbl, dtype=self.target_type) )\n",
    "        else:\n",
    "            return torch.from_numpy( np.array( pic, dtype=np.float32).transpose(2, 0, 1) ), torch.from_numpy( np.array( lbl, dtype=self.target_type) )\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '()'\n",
    "\n",
    "class ExtNormalize(object):\n",
    "    \"\"\"Normalize a tensor image with mean and standard deviation.\n",
    "    Given mean: ``(M1,...,Mn)`` and std: ``(S1,..,Sn)`` for ``n`` channels, this transform\n",
    "    will normalize each channel of the input ``torch.*Tensor`` i.e.\n",
    "    ``input[channel] = (input[channel] - mean[channel]) / std[channel]``\n",
    "    Args:\n",
    "        mean (sequence): Sequence of means for each channel.\n",
    "        std (sequence): Sequence of standard deviations for each channel.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, tensor, lbl):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
    "            tensor (Tensor): Tensor of label. A dummy input for ExtCompose\n",
    "        Returns:\n",
    "            Tensor: Normalized Tensor image.\n",
    "            Tensor: Unchanged Tensor label\n",
    "        \"\"\"\n",
    "        return F.normalize(tensor, self.mean, self.std), lbl\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n",
    "\n",
    "\n",
    "class ExtRandomCrop(object):\n",
    "    \"\"\"Crop the given PIL Image at a random location.\n",
    "    Args:\n",
    "        size (sequence or int): Desired output size of the crop. If size is an\n",
    "            int instead of sequence like (h, w), a square crop (size, size) is\n",
    "            made.\n",
    "        padding (int or sequence, optional): Optional padding on each border\n",
    "            of the image. Default is 0, i.e no padding. If a sequence of length\n",
    "            4 is provided, it is used to pad left, top, right, bottom borders\n",
    "            respectively.\n",
    "        pad_if_needed (boolean): It will pad the image if smaller than the\n",
    "            desired size to avoid raising an exception.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size, padding=0, pad_if_needed=False):\n",
    "        if isinstance(size, numbers.Number):\n",
    "            self.size = (int(size), int(size))\n",
    "        else:\n",
    "            self.size = size\n",
    "        self.padding = padding\n",
    "        self.pad_if_needed = pad_if_needed\n",
    "\n",
    "    @staticmethod\n",
    "    def get_params(img, output_size):\n",
    "        \"\"\"Get parameters for ``crop`` for a random crop.\n",
    "        Args:\n",
    "            img (PIL Image): Image to be cropped.\n",
    "            output_size (tuple): Expected output size of the crop.\n",
    "        Returns:\n",
    "            tuple: params (i, j, h, w) to be passed to ``crop`` for random crop.\n",
    "        \"\"\"\n",
    "        w, h = img.size\n",
    "        th, tw = output_size\n",
    "        if w == tw and h == th:\n",
    "            return 0, 0, h, w\n",
    "\n",
    "        i = random.randint(0, h - th)\n",
    "        j = random.randint(0, w - tw)\n",
    "        return i, j, th, tw\n",
    "\n",
    "    def __call__(self, img, lbl):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (PIL Image): Image to be cropped.\n",
    "            lbl (PIL Image): Label to be cropped.\n",
    "        Returns:\n",
    "            PIL Image: Cropped image.\n",
    "            PIL Image: Cropped label.\n",
    "        \"\"\"\n",
    "        assert img.size == lbl.size, 'size of img and lbl should be the same. %s, %s'%(img.size, lbl.size)\n",
    "        if self.padding > 0:\n",
    "            img = F.pad(img, self.padding)\n",
    "            lbl = F.pad(lbl, self.padding)\n",
    "\n",
    "        # pad the width if needed\n",
    "        if self.pad_if_needed and img.size[0] < self.size[1]:\n",
    "            img = F.pad(img, padding=int((1 + self.size[1] - img.size[0]) / 2))\n",
    "            lbl = F.pad(lbl, padding=int((1 + self.size[1] - lbl.size[0]) / 2))\n",
    "\n",
    "        # pad the height if needed\n",
    "        if self.pad_if_needed and img.size[1] < self.size[0]:\n",
    "            img = F.pad(img, padding=int((1 + self.size[0] - img.size[1]) / 2))\n",
    "            lbl = F.pad(lbl, padding=int((1 + self.size[0] - lbl.size[1]) / 2))\n",
    "\n",
    "        i, j, h, w = self.get_params(img, self.size)\n",
    "\n",
    "        return F.crop(img, i, j, h, w), F.crop(lbl, i, j, h, w)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(size={0}, padding={1})'.format(self.size, self.padding)\n",
    "\n",
    "\n",
    "class ExtResize(object):\n",
    "    \"\"\"Resize the input PIL Image to the given size.\n",
    "    Args:\n",
    "        size (sequence or int): Desired output size. If size is a sequence like\n",
    "            (h, w), output size will be matched to this. If size is an int,\n",
    "            smaller edge of the image will be matched to this number.\n",
    "            i.e, if height > width, then image will be rescaled to\n",
    "            (size * height / width, size)\n",
    "        interpolation (int, optional): Desired interpolation. Default is\n",
    "            ``PIL.Image.BILINEAR``\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size, interpolation=Image.BILINEAR):\n",
    "        assert isinstance(size, int) or (isinstance(size, collections.Iterable) and len(size) == 2)\n",
    "        self.size = size\n",
    "        self.interpolation = interpolation\n",
    "\n",
    "    def __call__(self, img, lbl):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (PIL Image): Image to be scaled.\n",
    "        Returns:\n",
    "            PIL Image: Rescaled image.\n",
    "        \"\"\"\n",
    "        return F.resize(img, self.size, self.interpolation), F.resize(lbl, self.size, Image.NEAREST)\n",
    "\n",
    "    def __repr__(self):\n",
    "        interpolate_str = _pil_interpolation_to_str[self.interpolation]\n",
    "        return self.__class__.__name__ + '(size={0}, interpolation={1})'.format(self.size, interpolate_str) \n",
    "    \n",
    "class ExtColorJitter(object):\n",
    "    \"\"\"Randomly change the brightness, contrast and saturation of an image.\n",
    "\n",
    "    Args:\n",
    "        brightness (float or tuple of float (min, max)): How much to jitter brightness.\n",
    "            brightness_factor is chosen uniformly from [max(0, 1 - brightness), 1 + brightness]\n",
    "            or the given [min, max]. Should be non negative numbers.\n",
    "        contrast (float or tuple of float (min, max)): How much to jitter contrast.\n",
    "            contrast_factor is chosen uniformly from [max(0, 1 - contrast), 1 + contrast]\n",
    "            or the given [min, max]. Should be non negative numbers.\n",
    "        saturation (float or tuple of float (min, max)): How much to jitter saturation.\n",
    "            saturation_factor is chosen uniformly from [max(0, 1 - saturation), 1 + saturation]\n",
    "            or the given [min, max]. Should be non negative numbers.\n",
    "        hue (float or tuple of float (min, max)): How much to jitter hue.\n",
    "            hue_factor is chosen uniformly from [-hue, hue] or the given [min, max].\n",
    "            Should have 0<= hue <= 0.5 or -0.5 <= min <= max <= 0.5.\n",
    "    \"\"\"\n",
    "    def __init__(self, brightness=0, contrast=0, saturation=0, hue=0):\n",
    "        self.brightness = self._check_input(brightness, 'brightness')\n",
    "        self.contrast = self._check_input(contrast, 'contrast')\n",
    "        self.saturation = self._check_input(saturation, 'saturation')\n",
    "        self.hue = self._check_input(hue, 'hue', center=0, bound=(-0.5, 0.5),\n",
    "                                     clip_first_on_zero=False)\n",
    "\n",
    "    def _check_input(self, value, name, center=1, bound=(0, float('inf')), clip_first_on_zero=True):\n",
    "        if isinstance(value, numbers.Number):\n",
    "            if value < 0:\n",
    "                raise ValueError(\"If {} is a single number, it must be non negative.\".format(name))\n",
    "            value = [center - value, center + value]\n",
    "            if clip_first_on_zero:\n",
    "                value[0] = max(value[0], 0)\n",
    "        elif isinstance(value, (tuple, list)) and len(value) == 2:\n",
    "            if not bound[0] <= value[0] <= value[1] <= bound[1]:\n",
    "                raise ValueError(\"{} values should be between {}\".format(name, bound))\n",
    "        else:\n",
    "            raise TypeError(\"{} should be a single number or a list/tuple with lenght 2.\".format(name))\n",
    "\n",
    "        # if value is 0 or (1., 1.) for brightness/contrast/saturation\n",
    "        # or (0., 0.) for hue, do nothing\n",
    "        if value[0] == value[1] == center:\n",
    "            value = None\n",
    "        return value\n",
    "\n",
    "    @staticmethod\n",
    "    def get_params(brightness, contrast, saturation, hue):\n",
    "        \"\"\"Get a randomized transform to be applied on image.\n",
    "\n",
    "        Arguments are same as that of __init__.\n",
    "\n",
    "        Returns:\n",
    "            Transform which randomly adjusts brightness, contrast and\n",
    "            saturation in a random order.\n",
    "        \"\"\"\n",
    "        transforms = []\n",
    "\n",
    "        if brightness is not None:\n",
    "            brightness_factor = random.uniform(brightness[0], brightness[1])\n",
    "            transforms.append(Lambda(lambda img: F.adjust_brightness(img, brightness_factor)))\n",
    "\n",
    "        if contrast is not None:\n",
    "            contrast_factor = random.uniform(contrast[0], contrast[1])\n",
    "            transforms.append(Lambda(lambda img: F.adjust_contrast(img, contrast_factor)))\n",
    "\n",
    "        if saturation is not None:\n",
    "            saturation_factor = random.uniform(saturation[0], saturation[1])\n",
    "            transforms.append(Lambda(lambda img: F.adjust_saturation(img, saturation_factor)))\n",
    "\n",
    "        if hue is not None:\n",
    "            hue_factor = random.uniform(hue[0], hue[1])\n",
    "            transforms.append(Lambda(lambda img: F.adjust_hue(img, hue_factor)))\n",
    "\n",
    "        random.shuffle(transforms)\n",
    "        transform = Compose(transforms)\n",
    "\n",
    "        return transform\n",
    "\n",
    "    def __call__(self, img, lbl):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (PIL Image): Input image.\n",
    "\n",
    "        Returns:\n",
    "            PIL Image: Color jittered image.\n",
    "        \"\"\"\n",
    "        transform = self.get_params(self.brightness, self.contrast,\n",
    "                                    self.saturation, self.hue)\n",
    "        return transform(img), lbl\n",
    "\n",
    "    def __repr__(self):\n",
    "        format_string = self.__class__.__name__ + '('\n",
    "        format_string += 'brightness={0}'.format(self.brightness)\n",
    "        format_string += ', contrast={0}'.format(self.contrast)\n",
    "        format_string += ', saturation={0}'.format(self.saturation)\n",
    "        format_string += ', hue={0})'.format(self.hue)\n",
    "        return format_string\n",
    "\n",
    "class Lambda(object):\n",
    "    \"\"\"Apply a user-defined lambda as a transform.\n",
    "\n",
    "    Args:\n",
    "        lambd (function): Lambda/function to be used for transform.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, lambd):\n",
    "        assert callable(lambd), repr(type(lambd).__name__) + \" object is not callable\"\n",
    "        self.lambd = lambd\n",
    "\n",
    "    def __call__(self, img):\n",
    "        return self.lambd(img)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '()'\n",
    "\n",
    "\n",
    "class Compose(object):\n",
    "    \"\"\"Composes several transforms together.\n",
    "\n",
    "    Args:\n",
    "        transforms (list of ``Transform`` objects): list of transforms to compose.\n",
    "\n",
    "    Example:\n",
    "        >>> transforms.Compose([\n",
    "        >>>     transforms.CenterCrop(10),\n",
    "        >>>     transforms.ToTensor(),\n",
    "        >>> ])\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, img):\n",
    "        for t in self.transforms:\n",
    "            img = t(img)\n",
    "        return img\n",
    "\n",
    "    def __repr__(self):\n",
    "        format_string = self.__class__.__name__ + '('\n",
    "        for t in self.transforms:\n",
    "            format_string += '\\n'\n",
    "            format_string += '    {0}'.format(t)\n",
    "        format_string += '\\n)'\n",
    "        return format_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "33fa95aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from collections import namedtuple\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class Satellites(data.Dataset):\n",
    "    \"\"\"Cityscapes <http://www.cityscapes-dataset.com/> Dataset.\n",
    "    \n",
    "    **Parameters:**\n",
    "        - **root** (string): Root directory of dataset where directory 'leftImg8bit' and 'gtFine' or 'gtCoarse' are located.\n",
    "        - **split** (string, optional): The image split to use, 'train', 'test' or 'val' if mode=\"gtFine\" otherwise 'train', 'train_extra' or 'val'\n",
    "        - **mode** (string, optional): The quality mode to use, 'gtFine' or 'gtCoarse' or 'color'. Can also be a list to output a tuple with all specified target types.\n",
    "        - **transform** (callable, optional): A function/transform that takes in a PIL image and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "        - **target_transform** (callable, optional): A function/transform that takes in the target and transforms it.\n",
    "    \"\"\"\n",
    "\n",
    "    # Based on sia\n",
    "    SatellitesClass = namedtuple('SatellitesClass', ['name', 'id', 'train_id', 'category', 'category_id',\n",
    "                                                     'has_instances', 'ignore_in_eval', 'color'])\n",
    "    #class\n",
    "    classes = [\n",
    "        SatellitesClass('unlabeled',            0, 255, 'void', 0, False, True, (0, 0, 0)),\n",
    "        SatellitesClass('road',                 1, 255, 'flat', 1, False, False, (128, 64, 128)),\n",
    "        SatellitesClass('building',             2, 1, 'flat', 1, True, False, (70, 70, 70)),\n",
    "    ]\n",
    "\n",
    "    train_id_to_color = [c.color for c in classes if (c.train_id != -1 and c.train_id != 255)]\n",
    "    train_id_to_color.append([0, 0, 0])\n",
    "    train_id_to_color = np.array(train_id_to_color)\n",
    "    id_to_train_id = np.array([c.train_id for c in classes])\n",
    "    \n",
    "    #train_id_to_color = [(0, 0, 0), (128, 64, 128), (70, 70, 70), (153, 153, 153), (107, 142, 35),\n",
    "    #                      (70, 130, 180), (220, 20, 60), (0, 0, 142)]\n",
    "    #train_id_to_color = np.array(train_id_to_color)\n",
    "    #id_to_train_id = np.array([c.category_id for c in classes], dtype='uint8') - 1\n",
    "\n",
    "    def __init__(self, root, split='train', mode='gtfine', target_type='sia', transform=None):\n",
    "        root = '/home/aiffel-dj54/aiffel/siaiffel/DeepLabV3Plus-Pytorch-master/datasets/data/SIA/buildings'\n",
    "        self.root = os.path.expanduser(root)\n",
    "        \n",
    "        self.mode = 'gtFine'\n",
    "        self.target_type = target_type\n",
    "        self.images_dir = os.path.join(self.root, 'leftImg8bit', split)\n",
    "\n",
    "        self.targets_dir = os.path.join(self.root, self.mode, split)\n",
    "        self.transform = transform\n",
    "\n",
    "        self.split = split\n",
    "        self.images = []\n",
    "        self.targets = []\n",
    "\n",
    "        if split not in ['train', 'test', 'val']:\n",
    "            raise ValueError('Invalid split for mode! Please use split=\"train\", split=\"test\"'\n",
    "                             ' or split=\"val\"')\n",
    "\n",
    "        if not os.path.isdir(self.images_dir) or not os.path.isdir(self.targets_dir):\n",
    "            raise RuntimeError('Dataset not found or incomplete. Please make sure all required folders for the'\n",
    "                               ' specified \"split\" and \"mode\" are inside the \"root\" directory')\n",
    "        \n",
    "        #for city in os.listdir(self.images_dir):\n",
    "            \n",
    "        img_dir = os.path.join(self.images_dir)\n",
    "        target_dir = os.path.join(self.targets_dir)\n",
    "        \n",
    "        for file_name in os.listdir(img_dir):\n",
    "            self.images.append(os.path.join(img_dir, file_name))\n",
    "            target_name = '{}{}'.format(file_name.split('.')[0],\n",
    "                                         self._get_target_suffix(self.mode, self.target_type))\n",
    "            self.targets.append(os.path.join(target_dir, target_name))\n",
    "\n",
    "    @classmethod\n",
    "    def encode_target(cls, target):\n",
    "        return cls.id_to_train_id[np.array(target)]\n",
    "\n",
    "    @classmethod\n",
    "    def decode_target(cls, target):\n",
    "        target[target == 255] = 1\n",
    "        #target = target.astype('uint8') + 1\n",
    "        return cls.train_id_to_color[target]\n",
    "    \n",
    "    def make_encode_target(self, target):\n",
    "        target = cv2.cvtColor(target, cv2.COLOR_BGR2GRAY)\n",
    "        ret, dst = cv2.threshold(target, 20, 1, cv2.THRESH_BINARY)\n",
    "        return dst\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is a tuple of all target types if target_type is a list with more\n",
    "            than one item. Otherwise target is a json object if target_type=\"polygon\", else the image segmentation.\n",
    "        \"\"\"\n",
    "        image = Image.open(self.images[index]).convert('RGB')\n",
    "        target = Image.open(self.targets[index])\n",
    "        \n",
    "        if self.transform:\n",
    "            image, target = self.transform(image, target)\n",
    "        target = np.array(target)\n",
    "        target = self.make_encode_target(target)\n",
    "        target = np.array(target, dtype='int')\n",
    "        \n",
    "        return image, target\n",
    "\n",
    "    def __getimg__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is a tuple of all target types if target_type is a list with more\n",
    "            than one item. Otherwise target is a json object if target_type=\"polygon\", else the image segmentation.\n",
    "        \"\"\"\n",
    "        image = Image.open(self.images[index]).convert('RGB')\n",
    "        print(self.images[index])\n",
    "        #target = Image.open(self.targets[index])\n",
    "        #if self.transform:\n",
    "        #    image, target = self.transform(image, target)\n",
    "        #target = self.encode_target(target)\n",
    "        return image #, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def _load_json(self, path):\n",
    "        with open(path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        return data\n",
    "\n",
    "    def _get_target_suffix(self, mode, target_type):\n",
    "        if target_type == 'instance':\n",
    "            return '{}_instanceIds.png'.format(mode)\n",
    "        elif target_type == 'semantic':\n",
    "            return '{}_labelIds.png'.format(mode)\n",
    "        elif target_type == 'color':\n",
    "            return '{}_color.png'.format(mode)\n",
    "        elif target_type == 'polygon':\n",
    "            return '{}_polygons.json'.format(mode)\n",
    "        elif target_type == 'depth':\n",
    "            return '{}_disparity.png'.format(mode)\n",
    "        elif target_type == 'sia':\n",
    "            return '.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6f1c736b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from collections import namedtuple\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class Satellites(data.Dataset):\n",
    "    \"\"\"Cityscapes <http://www.cityscapes-dataset.com/> Dataset.\n",
    "    \n",
    "    **Parameters:**\n",
    "        - **root** (string): Root directory of dataset where directory 'leftImg8bit' and 'gtFine' or 'gtCoarse' are located.\n",
    "        - **split** (string, optional): The image split to use, 'train', 'test' or 'val' if mode=\"gtFine\" otherwise 'train', 'train_extra' or 'val'\n",
    "        - **mode** (string, optional): The quality mode to use, 'gtFine' or 'gtCoarse' or 'color'. Can also be a list to output a tuple with all specified target types.\n",
    "        - **transform** (callable, optional): A function/transform that takes in a PIL image and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "        - **target_transform** (callable, optional): A function/transform that takes in the target and transforms it.\n",
    "    \"\"\"\n",
    "\n",
    "    # Based on sia\n",
    "    SatellitesClass = namedtuple('SatellitesClass', ['name', 'id', 'train_id', 'category', 'category_id',\n",
    "                                                     'has_instances', 'ignore_in_eval', 'color'])\n",
    "    #class\n",
    "    classes = [\n",
    "        SatellitesClass('unlabeled',            0, 255, 'void', 0, False, True, (0, 0, 0)),\n",
    "        SatellitesClass('road',                 1, 255, 'flat', 1, False, False, (128, 64, 128)),\n",
    "        SatellitesClass('building',             2, 1, 'flat', 1, True, False, (70, 70, 70)),\n",
    "    ]\n",
    "\n",
    "    train_id_to_color = [c.color for c in classes if (c.train_id != -1 and c.train_id != 255)]\n",
    "    train_id_to_color.append([0, 0, 0])\n",
    "    train_id_to_color = np.array(train_id_to_color)\n",
    "    id_to_train_id = np.array([c.train_id for c in classes])\n",
    "    \n",
    "    #train_id_to_color = [(0, 0, 0), (128, 64, 128), (70, 70, 70), (153, 153, 153), (107, 142, 35),\n",
    "    #                      (70, 130, 180), (220, 20, 60), (0, 0, 142)]\n",
    "    #train_id_to_color = np.array(train_id_to_color)\n",
    "    #id_to_train_id = np.array([c.category_id for c in classes], dtype='uint8') - 1\n",
    "\n",
    "    def __init__(self, root, split='train', mode='gtfine', target_type='sia', transform=None):\n",
    "        root = '/home/aiffel-dj54/aiffel/siaiffel/DeepLabV3Plus-Pytorch-master/datasets/data/SIA/buildings'\n",
    "        self.root = os.path.expanduser(root)\n",
    "        \n",
    "        self.mode = 'gtFine'\n",
    "        self.target_type = target_type\n",
    "        self.images_dir = os.path.join(self.root, 'leftImg8bit', split)\n",
    "\n",
    "        self.targets_dir = os.path.join(self.root, self.mode, split)\n",
    "        self.transform = transform\n",
    "\n",
    "        self.split = split\n",
    "        self.images = []\n",
    "        self.targets = []\n",
    "\n",
    "        if split not in ['train', 'test', 'val']:\n",
    "            raise ValueError('Invalid split for mode! Please use split=\"train\", split=\"test\"'\n",
    "                             ' or split=\"val\"')\n",
    "\n",
    "        if not os.path.isdir(self.images_dir) or not os.path.isdir(self.targets_dir):\n",
    "            raise RuntimeError('Dataset not found or incomplete. Please make sure all required folders for the'\n",
    "                               ' specified \"split\" and \"mode\" are inside the \"root\" directory')\n",
    "        \n",
    "        #for city in os.listdir(self.images_dir):\n",
    "            \n",
    "        img_dir = os.path.join(self.images_dir)\n",
    "        target_dir = os.path.join(self.targets_dir)\n",
    "        \n",
    "        for file_name in os.listdir(img_dir):\n",
    "            self.images.append(os.path.join(img_dir, file_name))\n",
    "            target_name = '{}{}'.format(file_name.split('.')[0],\n",
    "                                         self._get_target_suffix(self.mode, self.target_type))\n",
    "            self.targets.append(os.path.join(target_dir, target_name))\n",
    "\n",
    "    @classmethod\n",
    "    def encode_target(cls, target):\n",
    "        return cls.id_to_train_id[np.array(target)]\n",
    "\n",
    "    @classmethod\n",
    "    def decode_target(cls, target):\n",
    "        target[target == 255] = 1\n",
    "        #target = target.astype('uint8') + 1\n",
    "        return cls.train_id_to_color[target]\n",
    "    \n",
    "    def make_encode_target(self, target):\n",
    "        target = cv2.cvtColor(target, cv2.COLOR_BGR2GRAY)\n",
    "        ret, dst = cv2.threshold(target, 20, 1, cv2.THRESH_BINARY)\n",
    "        return dst\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is a tuple of all target types if target_type is a list with more\n",
    "            than one item. Otherwise target is a json object if target_type=\"polygon\", else the image segmentation.\n",
    "        \"\"\"\n",
    "        image = Image.open(self.images[index]).convert('RGB')\n",
    "        target = Image.open(self.targets[index])\n",
    "        \n",
    "        if self.transform:\n",
    "            image, target = self.transform(image, target)\n",
    "        target = np.array(target)\n",
    "        target = self.make_encode_target(target)\n",
    "        target = np.array(target, dtype='int')\n",
    "        \n",
    "        return image, target\n",
    "\n",
    "    def __getimg__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is a tuple of all target types if target_type is a list with more\n",
    "            than one item. Otherwise target is a json object if target_type=\"polygon\", else the image segmentation.\n",
    "        \"\"\"\n",
    "        image = Image.open(self.images[index]).convert('RGB')\n",
    "        print(self.images[index])\n",
    "        #target = Image.open(self.targets[index])\n",
    "        #if self.transform:\n",
    "        #    image, target = self.transform(image, target)\n",
    "        #target = self.encode_target(target)\n",
    "        return image #, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def _load_json(self, path):\n",
    "        with open(path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        return data\n",
    "\n",
    "    def _get_target_suffix(self, mode, target_type):\n",
    "        if target_type == 'instance':\n",
    "            return '{}_instanceIds.png'.format(mode)\n",
    "        elif target_type == 'semantic':\n",
    "            return '{}_labelIds.png'.format(mode)\n",
    "        elif target_type == 'color':\n",
    "            return '{}_color.png'.format(mode)\n",
    "        elif target_type == 'polygon':\n",
    "            return '{}_polygons.json'.format(mode)\n",
    "        elif target_type == 'depth':\n",
    "            return '{}_disparity.png'.format(mode)\n",
    "        elif target_type == 'sia':\n",
    "            return '.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "13eb39bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = '/home/aiffel-dj54/aiffel/siaiffel/DeepLabV3Plus-Pytorch-master/datasets/data/SIA/buildings'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4bf6e105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(opts):\n",
    "    \"\"\" Dataset And Augmentation\n",
    "    \"\"\"\n",
    "    if opts == 'cityscapes':\n",
    "        train_transform = ExtCompose([\n",
    "            #et.ExtResize( 512 ),\n",
    "            ExtRandomCrop(size=(512, 512)),\n",
    "            ExtColorJitter( brightness=0.5, contrast=0.5, saturation=0.5 ),\n",
    "            ExtRandomHorizontalFlip(),\n",
    "            ExtToTensor(),\n",
    "            ExtNormalize(mean=[0.485, 0.456, 0.406],\n",
    "                            std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "\n",
    "        val_transform = ExtCompose([\n",
    "            #et.ExtResize( 512 ),\n",
    "            ExtToTensor(),\n",
    "            ExtNormalize(mean=[0.485, 0.456, 0.406],\n",
    "                            std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "\n",
    "        train_dst = Cityscapes(root=data_root,\n",
    "                               split='train', transform=train_transform)\n",
    "        val_dst = Cityscapes(root=data_root,\n",
    "                             split='val', transform=val_transform)\n",
    "#trnasforms  \n",
    "#satellites 추가 \n",
    "    if opts == 'satellites':\n",
    "        train_transform = ExtCompose([\n",
    "            #et.ExtResize( 512 ),\n",
    "            ExtRandomCrop(size=(512, 512)),\n",
    "            ExtColorJitter( brightness=0.5, contrast=0.5, saturation=0.5 ),\n",
    "            ExtRandomHorizontalFlip(),\n",
    "            ExtToTensor(),\n",
    "            ExtNormalize(mean=[0.485, 0.456, 0.406],\n",
    "                            std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "\n",
    "        val_transform = ExtCompose([\n",
    "            #et.ExtResize( 512 ),\n",
    "            ExtToTensor(),\n",
    "            ExtNormalize(mean=[0.485, 0.456, 0.406],\n",
    "                            std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "#datasets\n",
    "        train_dst = Satellites(root=data_root,\n",
    "                               split='train', transform=train_transform)\n",
    "        val_dst = Satellites(root=data_root,\n",
    "                             split='val', transform=val_transform)\n",
    "    return train_dst, val_dst\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplab",
   "language": "python",
   "name": "deeplab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
